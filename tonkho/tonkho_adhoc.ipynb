{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default bq project:  spatial-vision-343005.biteam\n"
     ]
    }
   ],
   "source": [
    "from utils.df_handle import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dag_runs': [{'conf': {},\n",
       "   'dag_id': 'DMS_MASTER_CUSTOMER',\n",
       "   'dag_run_id': 'scheduled__2022-07-12T18:00:00+00:00',\n",
       "   'end_date': '2022-07-13T18:00:22.315811+00:00',\n",
       "   'execution_date': '2022-07-12T18:00:00+00:00',\n",
       "   'external_trigger': False,\n",
       "   'start_date': '2022-07-13T18:00:00.964662+00:00',\n",
       "   'state': 'success'}],\n",
       " 'total_entries': 8}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BoilerPlate\n",
    "import pendulum\n",
    "from airflow import DAG\n",
    "from airflow.operators.dummy_operator import DummyOperator\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "\n",
    "local_tz = pendulum.timezone(\"Asia/Bangkok\")\n",
    "\n",
    "name='TonKhoAdHoc'\n",
    "prefix='SC_'\n",
    "\n",
    "dag_params = {\n",
    "    'owner': 'airflow',\n",
    "    \"depends_on_past\": False,\n",
    "    'start_date': datetime(2022, 4, 2, tzinfo=local_tz),\n",
    "    'email_on_failure': True,\n",
    "    'email_on_retry': False,\n",
    "    'email':['duyvq@merapgroup.com', 'vanquangduy10@gmail.com'],\n",
    "    'do_xcom_push': False,\n",
    "    'execution_timeout':timedelta(seconds=300)\n",
    "    # 'retries': 3,\n",
    "    # 'retry_delay': timedelta(minutes=10),\n",
    "}\n",
    "\n",
    "dag = DAG(prefix+name,\n",
    "          catchup=False,\n",
    "          default_args=dag_params,\n",
    "          schedule_interval= '@once',\n",
    "          tags=[prefix+name, 'adhoc']\n",
    ")\n",
    "\n",
    "csv_path = '/usr/local/airflow/plugins'+'/'\n",
    "### END BOILERPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.df_handle import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1 if datetime.now().weekday() == 0 else 1\n",
    "datenow = datetime.now().strftime(\"%Y%m%d\")\n",
    "datenow_add1 = (datetime.now() + timedelta(days=x)).strftime(\"%Y%m%d\")\n",
    "datenow_mns1 = (datetime.now() - timedelta(days=x)).strftime(\"%Y%m%d\")\n",
    "fdom = datetime.now().replace(day=1).strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_csv(csv_path+f\"{datenow_mns1}_DF5.csv\")\n",
    "df5.chinhanh.fillna(\"NA\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert checkdup(df5,1,['masanpham','chinhanh']).sum() == 0, \"MSP & Chi Nhanh khong duoc trung\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map new data 13/01\n",
    "HDDURL = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTlHJ6SB5QNdaHdEaJlRnU7nKcLI2Haj6YlebHtqMvJ-GKsmAZWRvWa5j5dKBY8INF2vSd1fSJlTrXs/pub?gid=0&single=true&output=csv'\n",
    "_df = pd.read_csv(HDDURL, dayfirst=True, parse_dates=['Ngay(dd/mm/yyyy)'])\n",
    "lst = ['ngay','masanpham', 'tensanpham', 'soluonghdd1', 'chinhanh', 'solo', 'exdate', 'soluonghdd']\n",
    "# lst = ['ngay','masanpham', 'tensanpham', 'chinhanh','soluonghdd1','soluonghdd']\n",
    "_df.columns = lst\n",
    "_df = _df[_df.masanpham.notna()]\n",
    "_df.chinhanh.fillna(\"NA\", inplace=True)\n",
    "drop_cols(_df,['ngay','soluonghdd1', 'solo', 'exdate'])\n",
    "_df = pivot(_df, ['masanpham', 'chinhanh'], {'soluonghdd':np.sum})\n",
    "\n",
    "# Update 11/02/2022\n",
    "df5_dict = df5[['masanpham','tensanpham','donvi']].copy()\n",
    "df5_dict.drop_duplicates(inplace=True)\n",
    "_df = _df.merge(df5_dict, how='left', on='masanpham')\n",
    "# Update 11/02/2022\n",
    "df5_dict = df5[['chinhanh','songaynhan']].copy()\n",
    "df5_dict.drop_duplicates(inplace=True)\n",
    "_df = _df.merge(df5_dict, how='left', on='chinhanh')\n",
    "\n",
    "_df['tonao'] = 0\n",
    "_df['toncn'] = 0\n",
    "_df['tonhcm'] = 0\n",
    "_df['tonmerap'] = 0\n",
    "_df['tonvime'] = 0\n",
    "_df['toncn_huy'] = 0\n",
    "_df['tonhcm_huy'] = 0\n",
    "\n",
    "_df.columns = ['masanpham','chinhanh','tonhangdiduong','tensanpham','donvi','songaynhan','tonao','toncn','tonhcm','tonmerap','tonvime', 'toncn_huy', 'tonhcm_huy']\n",
    "_df = _df[['masanpham', 'tensanpham', 'donvi', 'chinhanh', 'songaynhan', 'tonao', 'tonhangdiduong', 'toncn', 'tonhcm', 'tonmerap', 'tonvime', 'toncn_huy', 'tonhcm_huy']]\n",
    "df5 = union_all([df5, _df])\n",
    "df5 = pivot(df5, ['masanpham', 'tensanpham', 'donvi', 'chinhanh', 'songaynhan'], {'tonao':np.sum, 'tonhangdiduong':np.sum, 'toncn':np.sum, 'tonhcm':np.sum, 'tonmerap':np.sum, 'tonvime':np.sum, 'toncn_huy':np.sum, 'tonhcm_huy':np.sum})\n",
    "\n",
    "\n",
    "assert checkdup(df5,1,['masanpham','chinhanh']).sum() == 0, \"MSP & Chi Nhanh khong duoc trung\"\n",
    "\n",
    "NMURLTP = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRvmeMXGwa-2u-cCQmDRyXs__a8oLfcZk9yLyq1LupmdsvzulMVlxHublEJAKszBY-zmnl_Wm1KNnvZ/pub?gid=0&single=true&output=csv'\n",
    "nmtp = pd.read_csv(NMURLTP)\n",
    "# nmtp.columns = nmtp.iloc[0]\n",
    "headers = nmtp.iloc[0]\n",
    "nmtp  = pd.DataFrame(nmtp.values[1:], columns=headers)\n",
    "nmtp.columns = cleancols(nmtp)\n",
    "nmtp.columns = lower_col(nmtp)\n",
    "dk1 = nmtp.ten_phanam.notna()\n",
    "nmtp = nmtp[dk1].copy()\n",
    "nmtp = nmtp[['ten_phanam','convert']].copy()\n",
    "nmtp.convert = pd.to_numeric(nmtp.convert)\n",
    "dk2 = nmtp.convert != 0\n",
    "nmtp = nmtp[dk2].copy()\n",
    "nmtp['datatype'] = 'TP'\n",
    "\n",
    "# nmtp.convert.sum()\n",
    "\n",
    "NMURLBT = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRvmeMXGwa-2u-cCQmDRyXs__a8oLfcZk9yLyq1LupmdsvzulMVlxHublEJAKszBY-zmnl_Wm1KNnvZ/pub?gid=869914713&single=true&output=csv'\n",
    "nmbt = pd.read_csv(NMURLBT)\n",
    "nmbt.columns = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "nmbt = nmbt[[14,15]].copy()\n",
    "nmbt.columns = ['ten_phanam', 'convert']\n",
    "dk1 = nmbt.ten_phanam.notna()\n",
    "nmbt = nmbt[dk1].copy()\n",
    "nmbt.convert = pd.to_numeric(nmbt.convert)\n",
    "dk2 = nmbt.convert != 0\n",
    "nmbt = nmbt[dk2].copy()\n",
    "nmbt['datatype'] = 'BT'\n",
    "\n",
    "NMURLHH = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRvmeMXGwa-2u-cCQmDRyXs__a8oLfcZk9yLyq1LupmdsvzulMVlxHublEJAKszBY-zmnl_Wm1KNnvZ/pub?gid=1577909815&single=true&output=csv'\n",
    "nmhh = pd.read_csv(NMURLHH)\n",
    "nmhh.columns = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "nmhh = nmhh[[14,15]].copy()\n",
    "nmhh.columns = ['ten_phanam', 'convert']\n",
    "dk1 = nmhh.ten_phanam.notna()\n",
    "nmhh = nmhh[dk1].copy()\n",
    "nmhh.convert = pd.to_numeric(nmhh.convert)\n",
    "dk2 = nmhh.convert != 0\n",
    "nmhh = nmhh[dk2].copy()\n",
    "nmhh['datatype'] = 'HH'\n",
    "\n",
    "NM = union_all([nmtp,nmbt,nmhh])\n",
    "NM.columns = ['invtid','soluong','datatype']\n",
    "# dfnmid = get_ps_df(\"SELECT nhamayid, invtid FROM d_sc_invtid WHERE nhamayid NOTNULL\")\n",
    "# dfnmid = pd.read_csv('datacodenm.csv')\n",
    "# NM = NM.merge(dfnmid, how='left', on='nhamayid')\n",
    "# assert NM.invtid.isna().sum() == 0, \"NEW NM SKU FOUND\"\n",
    "# del(dfnmid)\n",
    "# NM = NM[NM.invtid.notna()]\n",
    "NM = pivot(NM, ['invtid', 'datatype'], {'soluong':np.sum})\n",
    "\n",
    "df5_dict = df5[['masanpham','tensanpham','donvi']].copy()\n",
    "df5_dict.drop_duplicates(inplace=True)\n",
    "\n",
    "NM.columns = ['masanpham', 'datatype', 'soluong']\n",
    "\n",
    "# ADDING Ton Theo PO & NM no PO\n",
    "THEOPO_URL = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRvmeMXGwa-2u-cCQmDRyXs__a8oLfcZk9yLyq1LupmdsvzulMVlxHublEJAKszBY-zmnl_Wm1KNnvZ/pub?gid=574959890&single=true&output=csv'\n",
    "nmtheopo = pd.read_csv(THEOPO_URL)\n",
    "\n",
    "nmtheopo.columns = cleancols(nmtheopo)\n",
    "nmtheopo.columns = lower_col(nmtheopo)\n",
    "\n",
    "nmtheopo.columns = ['mapn','dummy','nmnopo','tontheopo']\n",
    "\n",
    "nmpo = nmtheopo[['mapn','tontheopo']].copy()\n",
    "nmpo['datatype'] = 'PO'\n",
    "nmpo = nmpo[['mapn', 'datatype', 'tontheopo']]\n",
    "nmpo.columns = ['masanpham', 'datatype', 'soluong']\n",
    "\n",
    "nmno = nmtheopo[['mapn','nmnopo']].copy()\n",
    "nmno['datatype'] = 'NO'\n",
    "nmno = nmno[['mapn', 'datatype', 'nmnopo']]\n",
    "nmno.columns = ['masanpham', 'datatype', 'soluong']\n",
    "\n",
    "NM = union_all([NM,nmpo,nmno])\n",
    "\n",
    "# NM.to_clipboard()\n",
    "\n",
    "NM = NM.merge(df5_dict, how='left', on='masanpham')\n",
    "\n",
    "NM['chinhanh'] = 'NM'\n",
    "\n",
    "dk1 = NM['datatype'] == \"TP\"\n",
    "dk2 = NM['datatype'] == \"BT\"\n",
    "dk3 = NM['datatype'] == \"HH\"\n",
    "dk4 = NM['datatype'] == \"PO\"\n",
    "dk5 = NM['datatype'] == \"NO\"\n",
    "\n",
    "NM['tonnmtp'] = np.where(dk1, NM['soluong'], 0)\n",
    "NM['tonnmbt'] = np.where(dk2, NM['soluong'], 0)\n",
    "NM['tonnmhh'] = np.where(dk3, NM['soluong'], 0)\n",
    "NM['tonnmpo'] = np.where(dk4, NM['soluong'], 0)\n",
    "NM['tonnmno'] = np.where(dk5, NM['soluong'], 0)\n",
    "\n",
    "grouplst = ['masanpham', 'tensanpham', 'donvi', 'chinhanh']\n",
    "agg_dict = \\\n",
    "{\n",
    "'tonnmtp':np.sum,\n",
    "'tonnmbt':np.sum,\n",
    "'tonnmhh':np.sum,\n",
    "'tonnmpo':np.sum,\n",
    "'tonnmno':np.sum\n",
    "}\n",
    "\n",
    "NM = pivot(NM, grouplst, agg_dict)\n",
    "\n",
    "NM['songaynhan'] = 0\n",
    "NM['tonao'] = 0\n",
    "NM['tonhangdiduong'] = 0\n",
    "NM['toncn'] = 0\n",
    "NM['tonhcm'] = 0\n",
    "NM['tonmerap'] = 0\n",
    "NM['tonvime'] = 0\n",
    "NM['toncn_huy'] = 0\n",
    "NM['tonhcm_huy'] = 0\n",
    "\n",
    "NM = NM[['masanpham', 'tensanpham', 'donvi', 'chinhanh', 'songaynhan', 'tonao', 'tonhangdiduong', 'toncn', 'tonhcm',\n",
    "    'tonmerap', 'tonvime', 'toncn_huy', 'tonhcm_huy', 'tonnmtp', 'tonnmbt', 'tonnmhh', 'tonnmpo', 'tonnmno']]\n",
    "\n",
    "# NM.to_clipboard()\n",
    "\n",
    "df5['tonnmtp'] = 0\n",
    "df5['tonnmbt'] = 0\n",
    "df5['tonnmhh'] = 0\n",
    "df5['tonnmpo'] = 0\n",
    "df5['tonnmno'] = 0\n",
    "\n",
    "# union ton NM va ton DMS\n",
    "df5 = union_all([df5, NM])\n",
    "\n",
    "# df5.head()\n",
    "\n",
    "cur_day = datetime.now().day\n",
    "cur_month = datetime.now().month\n",
    "cur_year = datetime.now().year\n",
    "\n",
    "def get_3m_ago(cur_month=datetime.now().month, cur_year=datetime.now().year):\n",
    "    if cur_month - 3 < 0:\n",
    "        return [cur_month + 12 - 3, cur_year -1]\n",
    "    if cur_month - 3 == 0:\n",
    "        return [12, cur_year -1]\n",
    "    else:\n",
    "        return [cur_month - 3, cur_year]\n",
    "\n",
    "\n",
    "# lst = get_3m_ago()\n",
    "# start_date = datetime(lst[1], lst[0], cur_day).strftime(\"%Y%m%d\")\n",
    "# # start_date\n",
    "# query = f\"EXEC [pr_OM_RawdataSellOutPayroll_BI_v1] @Fromdate='{start_date}', @Todate='{datenow}'\"\n",
    "# SALES = get_ms_df(sql=query)\n",
    "# SALES.columns = cleancols(SALES)\n",
    "# SALES.columns = lower_col(SALES)\n",
    "\n",
    "# SALES = SALES[['masanpham', 'soluong', 'makho']]\n",
    "# dfsc = get_ps_df(\"select makho,chinhanh from d_sc_kho_chi_nhanh\")\n",
    "# dfsc.columns = ['makho','chinhanh_sc']\n",
    "# SALES = SALES.merge(dfsc, how=\"left\", on=\"makho\")\n",
    "# # SALES.head()\n",
    "# del(dfsc)\n",
    "# days = len(pd.date_range(start_date, datetime.now()))-13\n",
    "# SALES = pivot(SALES, ['masanpham', \"chinhanh_sc\"], {\"soluong\":np.sum})\n",
    "# SALES['avg_3m'] = round(SALES['soluong']/days,0)\n",
    "# # drop_cols(SALES, 'soluong')\n",
    "# SALES.columns = ['masanpham','chinhanh','soluong','avg_3m']\n",
    "\n",
    "bsql = \\\n",
    "\"\"\"\n",
    "with sales as \n",
    "(select masanpham,soluong,makho\n",
    "from biteam.f_sales\n",
    "where date(ngaychungtu)>=date_sub(current_date(),interval 3 month))\n",
    ",\n",
    "dfsc as \n",
    "(\n",
    "select distinct makho,chinhanh chinhanh_sc\n",
    "from biteam.d_sc_kho_chi_nhanh\n",
    ")\n",
    "\n",
    "select t1.masanpham, t2.chinhanh_sc as chinhanh,sum(t1.soluong) soluong,round(sum(t1.soluong)/(90-13),0) as avg_3m\n",
    "from sales t1\n",
    "left join dfsc t2 on t1.makho=t2.makho\n",
    "group by 1,2\n",
    "\"\"\"\n",
    "\n",
    "SALES = get_bq_df(bsql)\n",
    "\n",
    "# SALES.to_csv(csv_path+f'{prefix}{name}/'+f'{datenow}_SALES.csv', index=False)\n",
    "\n",
    "\n",
    "df6 = df5.merge(SALES, how = \"left\", on=['masanpham','chinhanh'])\n",
    "\n",
    "df6.soluong.fillna(0, inplace=True)\n",
    "df6.avg_3m.fillna(0, inplace=True)\n",
    "\n",
    "# df6['created_date'] = datetime(2022,1,24)\n",
    "df6['created_date'] = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "assert checkdup(df6,1,['masanpham','chinhanh']).sum() == 0, \"MSP & Chi Nhanh khong duoc trung\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['created_date'] = datetime(2022,9,28)\n",
    "df6['inserted_at2'] = datetime(2022,9,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del_psql = \\\n",
    "# f\"\"\"\n",
    "# DELETE from f_sc_daily_invt where created_date = '{datenow_mns1}'\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commit_psql(del_psql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted using execute_values() successfully..\n"
     ]
    }
   ],
   "source": [
    "# execute_values_insert(df6,'f_sc_daily_invt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datenow_mns1 = (datetime.now() - timedelta(days=2)).strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_bsql = \\\n",
    "f\"\"\"\n",
    "DELETE FROM `spatial-vision-343005.biteam.f_sc_daily_invt` where date(created_date) = '{datenow_mns1}'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DELETE FROM `spatial-vision-343005.biteam.f_sc_daily_invt` where date(created_date) = '20220928'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(del_bsql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_bq_query(del_bsql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_values_insert(df6, \"f_sc_daily_invt\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fb55849e6741974ce442ee684e971e1b6b22c29ca2b25c3b9069bf531e0354a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
