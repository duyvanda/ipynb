{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default bq project:  spatial-vision-343005.biteam\n"
     ]
    }
   ],
   "source": [
    "from utils.df_handle import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('20221027_DF4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_pickle(\"20221120_DF5.pickle\")\n",
    "df5.chinhanh.fillna(\"NA\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>masanpham</th>\n",
       "      <th>tensanpham</th>\n",
       "      <th>donvi</th>\n",
       "      <th>chinhanh</th>\n",
       "      <th>songaynhan</th>\n",
       "      <th>tonao</th>\n",
       "      <th>tonhangdiduong</th>\n",
       "      <th>toncn</th>\n",
       "      <th>tonhcm</th>\n",
       "      <th>tonmerap</th>\n",
       "      <th>tonvime</th>\n",
       "      <th>toncn_huy</th>\n",
       "      <th>tonhcm_huy</th>\n",
       "      <th>tonece</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [masanpham, tensanpham, donvi, chinhanh, songaynhan, tonao, tonhangdiduong, toncn, tonhcm, tonmerap, tonvime, toncn_huy, tonhcm_huy, tonece]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5[checkdup(df5, 2, subset=['masanpham','chinhanh'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDDURL = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTlHJ6SB5QNdaHdEaJlRnU7nKcLI2Haj6YlebHtqMvJ-GKsmAZWRvWa5j5dKBY8INF2vSd1fSJlTrXs/pub?gid=0&single=true&output=csv'\n",
    "_df = pd.read_csv(HDDURL, dayfirst=True, parse_dates=['Ngay(dd/mm/yyyy)'])\n",
    "lst = ['ngay','masanpham', 'tensanpham', 'soluonghdd1', 'chinhanh', 'solo', 'exdate', 'soluonghdd']\n",
    "# lst = ['ngay','masanpham', 'tensanpham', 'chinhanh','soluonghdd1','soluonghdd']\n",
    "_df.columns = lst\n",
    "_df = _df[_df.masanpham.notna()]\n",
    "_df.chinhanh.fillna(\"NA\", inplace=True)\n",
    "drop_cols(_df,['ngay','soluonghdd1', 'solo', 'exdate'])\n",
    "_df = pivot(_df, ['masanpham', 'chinhanh'], {'soluonghdd':np.sum})\n",
    "\n",
    "# Update 11/02/2022\n",
    "df5_dict = df5[['masanpham','tensanpham','donvi']].copy()\n",
    "df5_dict.drop_duplicates(inplace=True)\n",
    "_df = _df.merge(df5_dict, how='left', on='masanpham')\n",
    "# Update 11/02/2022\n",
    "df5_dict = df5[['chinhanh','songaynhan']].copy()\n",
    "df5_dict.drop_duplicates(inplace=True)\n",
    "_df = _df.merge(df5_dict, how='left', on='chinhanh')\n",
    "\n",
    "_df['tonao'] = 0\n",
    "_df['toncn'] = 0\n",
    "_df['tonhcm'] = 0\n",
    "_df['tonmerap'] = 0\n",
    "_df['tonvime'] = 0\n",
    "_df['toncn_huy'] = 0\n",
    "_df['tonhcm_huy'] = 0\n",
    "\n",
    "_df.columns = ['masanpham','chinhanh','tonhangdiduong','tensanpham','donvi','songaynhan','tonao','toncn','tonhcm','tonmerap','tonvime', 'toncn_huy', 'tonhcm_huy']\n",
    "_df = _df[['masanpham', 'tensanpham', 'donvi', 'chinhanh', 'songaynhan', 'tonao', 'tonhangdiduong', 'toncn', 'tonhcm', 'tonmerap', 'tonvime', 'toncn_huy', 'tonhcm_huy']]\n",
    "df5 = union_all([df5, _df])\n",
    "df5 = pivot(df5, ['masanpham', 'tensanpham', 'donvi', 'chinhanh', 'songaynhan'], {'tonao':np.sum, 'tonhangdiduong':np.sum, 'toncn':np.sum, 'tonhcm':np.sum, 'tonmerap':np.sum, 'tonvime':np.sum, 'toncn_huy':np.sum, 'tonhcm_huy':np.sum})\n",
    "\n",
    "\n",
    "assert checkdup(df5,1,['masanpham','chinhanh']).sum() == 0, \"MSP & Chi Nhanh khong duoc trung\"\n",
    "\n",
    "NMURLTP = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRvmeMXGwa-2u-cCQmDRyXs__a8oLfcZk9yLyq1LupmdsvzulMVlxHublEJAKszBY-zmnl_Wm1KNnvZ/pub?gid=0&single=true&output=csv'\n",
    "nmtp = pd.read_csv(NMURLTP)\n",
    "# nmtp.columns = nmtp.iloc[0]\n",
    "headers = nmtp.iloc[0]\n",
    "nmtp  = pd.DataFrame(nmtp.values[1:], columns=headers)\n",
    "nmtp.columns = cleancols(nmtp)\n",
    "nmtp.columns = lower_col(nmtp)\n",
    "dk1 = nmtp.ten_phanam.notna()\n",
    "nmtp = nmtp[dk1].copy()\n",
    "nmtp = nmtp[['ten_phanam','convert']].copy()\n",
    "nmtp.convert = pd.to_numeric(nmtp.convert)\n",
    "dk2 = nmtp.convert != 0\n",
    "nmtp = nmtp[dk2].copy()\n",
    "nmtp['datatype'] = 'TP'\n",
    "\n",
    "# nmtp.convert.sum()\n",
    "\n",
    "NMURLBT = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRvmeMXGwa-2u-cCQmDRyXs__a8oLfcZk9yLyq1LupmdsvzulMVlxHublEJAKszBY-zmnl_Wm1KNnvZ/pub?gid=869914713&single=true&output=csv'\n",
    "nmbt = pd.read_csv(NMURLBT)\n",
    "nmbt.columns = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "nmbt = nmbt[[14,15]].copy()\n",
    "nmbt.columns = ['ten_phanam', 'convert']\n",
    "dk1 = nmbt.ten_phanam.notna()\n",
    "nmbt = nmbt[dk1].copy()\n",
    "nmbt.convert = pd.to_numeric(nmbt.convert)\n",
    "dk2 = nmbt.convert != 0\n",
    "nmbt = nmbt[dk2].copy()\n",
    "nmbt['datatype'] = 'BT'\n",
    "\n",
    "NMURLHH = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRvmeMXGwa-2u-cCQmDRyXs__a8oLfcZk9yLyq1LupmdsvzulMVlxHublEJAKszBY-zmnl_Wm1KNnvZ/pub?gid=1577909815&single=true&output=csv'\n",
    "nmhh = pd.read_csv(NMURLHH)\n",
    "nmhh.columns = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "nmhh = nmhh[[14,15]].copy()\n",
    "nmhh.columns = ['ten_phanam', 'convert']\n",
    "dk1 = nmhh.ten_phanam.notna()\n",
    "nmhh = nmhh[dk1].copy()\n",
    "nmhh.convert = pd.to_numeric(nmhh.convert)\n",
    "dk2 = nmhh.convert != 0\n",
    "nmhh = nmhh[dk2].copy()\n",
    "nmhh['datatype'] = 'HH'\n",
    "\n",
    "NM = union_all([nmtp,nmbt,nmhh])\n",
    "NM.columns = ['invtid','soluong','datatype']\n",
    "# dfnmid = get_ps_df(\"SELECT nhamayid, invtid FROM d_sc_invtid WHERE nhamayid NOTNULL\")\n",
    "# dfnmid = pd.read_csv('datacodenm.csv')\n",
    "# NM = NM.merge(dfnmid, how='left', on='nhamayid')\n",
    "# assert NM.invtid.isna().sum() == 0, \"NEW NM SKU FOUND\"\n",
    "# del(dfnmid)\n",
    "# NM = NM[NM.invtid.notna()]\n",
    "NM = pivot(NM, ['invtid', 'datatype'], {'soluong':np.sum})\n",
    "\n",
    "df5_dict = df5[['masanpham','tensanpham','donvi']].copy()\n",
    "df5_dict.drop_duplicates(inplace=True)\n",
    "\n",
    "NM.columns = ['masanpham', 'datatype', 'soluong']\n",
    "\n",
    "# ADDING Ton Theo PO & NM no PO\n",
    "THEOPO_URL = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRvmeMXGwa-2u-cCQmDRyXs__a8oLfcZk9yLyq1LupmdsvzulMVlxHublEJAKszBY-zmnl_Wm1KNnvZ/pub?gid=574959890&single=true&output=csv'\n",
    "nmtheopo = pd.read_csv(THEOPO_URL)\n",
    "\n",
    "nmtheopo.columns = cleancols(nmtheopo)\n",
    "nmtheopo.columns = lower_col(nmtheopo)\n",
    "\n",
    "nmtheopo.columns = ['mapn','dummy','nmnopo','tontheopo']\n",
    "\n",
    "nmpo = nmtheopo[['mapn','tontheopo']].copy()\n",
    "nmpo['datatype'] = 'PO'\n",
    "nmpo = nmpo[['mapn', 'datatype', 'tontheopo']]\n",
    "nmpo.columns = ['masanpham', 'datatype', 'soluong']\n",
    "\n",
    "nmno = nmtheopo[['mapn','nmnopo']].copy()\n",
    "nmno['datatype'] = 'NO'\n",
    "nmno = nmno[['mapn', 'datatype', 'nmnopo']]\n",
    "nmno.columns = ['masanpham', 'datatype', 'soluong']\n",
    "\n",
    "NM = union_all([NM,nmpo,nmno])\n",
    "\n",
    "# NM.to_clipboard()\n",
    "\n",
    "NM = NM.merge(df5_dict, how='left', on='masanpham')\n",
    "\n",
    "NM['chinhanh'] = 'NM'\n",
    "\n",
    "dk1 = NM['datatype'] == \"TP\"\n",
    "dk2 = NM['datatype'] == \"BT\"\n",
    "dk3 = NM['datatype'] == \"HH\"\n",
    "dk4 = NM['datatype'] == \"PO\"\n",
    "dk5 = NM['datatype'] == \"NO\"\n",
    "\n",
    "NM['tonnmtp'] = np.where(dk1, NM['soluong'], 0)\n",
    "NM['tonnmbt'] = np.where(dk2, NM['soluong'], 0)\n",
    "NM['tonnmhh'] = np.where(dk3, NM['soluong'], 0)\n",
    "NM['tonnmpo'] = np.where(dk4, NM['soluong'], 0)\n",
    "NM['tonnmno'] = np.where(dk5, NM['soluong'], 0)\n",
    "\n",
    "grouplst = ['masanpham', 'tensanpham', 'donvi', 'chinhanh']\n",
    "agg_dict = \\\n",
    "{\n",
    "'tonnmtp':np.sum,\n",
    "'tonnmbt':np.sum,\n",
    "'tonnmhh':np.sum,\n",
    "'tonnmpo':np.sum,\n",
    "'tonnmno':np.sum\n",
    "}\n",
    "\n",
    "NM = pivot(NM, grouplst, agg_dict)\n",
    "\n",
    "NM['songaynhan'] = 0\n",
    "NM['tonao'] = 0\n",
    "NM['tonhangdiduong'] = 0\n",
    "NM['toncn'] = 0\n",
    "NM['tonhcm'] = 0\n",
    "NM['tonmerap'] = 0\n",
    "NM['tonvime'] = 0\n",
    "NM['toncn_huy'] = 0\n",
    "NM['tonhcm_huy'] = 0\n",
    "\n",
    "NM = NM[['masanpham', 'tensanpham', 'donvi', 'chinhanh', 'songaynhan', 'tonao', 'tonhangdiduong', 'toncn', 'tonhcm',\n",
    "'tonmerap', 'tonvime', 'toncn_huy', 'tonhcm_huy', 'tonnmtp', 'tonnmbt', 'tonnmhh', 'tonnmpo', 'tonnmno']]\n",
    "\n",
    "# NM.to_clipboard()\n",
    "\n",
    "df5['tonnmtp'] = 0\n",
    "df5['tonnmbt'] = 0\n",
    "df5['tonnmhh'] = 0\n",
    "df5['tonnmpo'] = 0\n",
    "df5['tonnmno'] = 0\n",
    "\n",
    "# union ton NM va ton DMS\n",
    "df5 = union_all([df5, NM])\n",
    "\n",
    "# df5.head()\n",
    "\n",
    "cur_day = datetime.now().day\n",
    "cur_month = datetime.now().month\n",
    "cur_year = datetime.now().year\n",
    "\n",
    "def get_3m_ago(cur_month=datetime.now().month, cur_year=datetime.now().year):\n",
    "    if cur_month - 3 < 0:\n",
    "        return [cur_month + 12 - 3, cur_year -1]\n",
    "    if cur_month - 3 == 0:\n",
    "        return [12, cur_year -1]\n",
    "    else:\n",
    "        return [cur_month - 3, cur_year]\n",
    "\n",
    "\n",
    "# lst = get_3m_ago()\n",
    "# start_date = datetime(lst[1], lst[0], cur_day).strftime(\"%Y%m%d\")\n",
    "# # start_date\n",
    "# query = f\"EXEC [pr_OM_RawdataSellOutPayroll_BI_v1] @Fromdate='{start_date}', @Todate='{datenow}'\"\n",
    "# SALES = get_ms_df(sql=query)\n",
    "# SALES.columns = cleancols(SALES)\n",
    "# SALES.columns = lower_col(SALES)\n",
    "\n",
    "# SALES = SALES[['masanpham', 'soluong', 'makho']]\n",
    "# dfsc = get_ps_df(\"select makho,chinhanh from d_sc_kho_chi_nhanh\")\n",
    "# dfsc.columns = ['makho','chinhanh_sc']\n",
    "# SALES = SALES.merge(dfsc, how=\"left\", on=\"makho\")\n",
    "# # SALES.head()\n",
    "# del(dfsc)\n",
    "# days = len(pd.date_range(start_date, datetime.now()))-13\n",
    "# SALES = pivot(SALES, ['masanpham', \"chinhanh_sc\"], {\"soluong\":np.sum})\n",
    "# SALES['avg_3m'] = round(SALES['soluong']/days,0)\n",
    "# # drop_cols(SALES, 'soluong')\n",
    "# SALES.columns = ['masanpham','chinhanh','soluong','avg_3m']\n",
    "\n",
    "bsql = \\\n",
    "\"\"\"\n",
    "with sales as \n",
    "(select masanpham,soluong,makho\n",
    "from biteam.f_sales\n",
    "where date(ngaychungtu)>=date_sub(current_date(),interval 3 month))\n",
    ",\n",
    "dfsc as \n",
    "(\n",
    "select distinct makho,chinhanh chinhanh_sc\n",
    "from biteam.d_sc_kho_chi_nhanh\n",
    ")\n",
    "\n",
    "select t1.masanpham, t2.chinhanh_sc as chinhanh,sum(t1.soluong) soluong,round(sum(t1.soluong)/(90-13),0) as avg_3m\n",
    "from sales t1\n",
    "left join dfsc t2 on t1.makho=t2.makho\n",
    "group by 1,2\n",
    "\"\"\"\n",
    "\n",
    "SALES = get_bq_df(bsql)\n",
    "\n",
    "# SALES.to_csv(csv_path+f'{prefix}{name}/'+f'{datenow}_SALES.csv', index=False)\n",
    "\n",
    "\n",
    "df6 = df5.merge(SALES, how = \"left\", on=['masanpham','chinhanh'])\n",
    "\n",
    "df6.soluong.fillna(0, inplace=True)\n",
    "df6.avg_3m.fillna(0, inplace=True)\n",
    "\n",
    "# df6['created_date'] = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "assert checkdup(df6,1,['masanpham','chinhanh']).sum() == 0, \"MSP & Chi Nhanh khong duoc trung\"\n",
    "\n",
    "# Update 25072022 phuonght2\n",
    "#xóa data ngày hiện tại\n",
    "# bq_ex = ''' DELETE FROM biteam.f_sc_daily_invt WHERE date(created_date) = date(current_date); '''\n",
    "# pg_ex = ''' DELETE FROM f_sc_daily_invt WHERE date(created_date) = date(current_date); '''\n",
    "\n",
    "# execute_bq_query(bq_ex)\n",
    "# commit_psql(pg_ex)\n",
    "\n",
    "# #input data mới\n",
    "# execute_values_insert(df6,'f_sc_daily_invt')\n",
    "\n",
    "# df6['inserted_at2'] = datetime.now()\n",
    "# bq_values_insert(df6, \"f_sc_daily_invt\", 2)\n",
    "# execute_bq_query(\"\"\"call `spatial-vision-343005.view_report.f_tonkhotonghop_daily`();\"\"\")\n",
    "\n",
    "# # điều kiện input\n",
    "# def update_tonkho():\n",
    "# dk  = datetime.now().strftime(\"%H:%M\") in {'11:00','12:00','14:00','23:45'}\n",
    "# if dk: tonkho()\n",
    "# else: print(\"Not a good time\", datetime.now().strftime(\"%H:%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['inserted_at2'] = datetime(2022,11,20,23)\n",
    "df6['created_date'] = datetime(2022,11,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_values_insert(df6, \"f_sc_daily_invt\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(553, 22)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fb55849e6741974ce442ee684e971e1b6b22c29ca2b25c3b9069bf531e0354a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
